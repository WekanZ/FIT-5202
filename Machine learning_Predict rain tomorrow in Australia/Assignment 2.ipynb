{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FIT5202 Data processing for big data Assignment 2\n",
    "\n",
    "##  Rain in Australia: Predict rain tomorrow in Australia \n",
    "\n",
    "Predicting rain or weather is a common problem in machine learning. Different machine                           learning algorithms can be used to model and predict rainfall. In this assignment, we ask                               you to complete the analysis to predict whether there will be rain tomorrow or not. In                                 particular, you are required to apply the tools of machine learning to visualize and                             predict the possibility of rainfall in Australia.   \n",
    "\n",
    "Required Datasets (available in Moodle):   \n",
    "- Rain in Australia (​weatherAUS.csv​)     \n",
    "\n",
    "The dataset is originally from Kaggle Dataset and can be found at ​this link​. It has been  modified to serve our purpose i.e. (to do the binary classification). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all the packages\n",
    "from pyspark import SparkContext, SparkConf \n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import BooleanType\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.classification import GBTClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  A.Creating Spark Session and Loading the Data \n",
    "\n",
    "### Step 01: Import Spark Session and initialize Spark  \n",
    "pyspark is the Spark Python API that exposes the Spark programming model to                           Python. You are already familiar with ​sparkContext from Assignment 1. ​sparkContext                       was used as a channel to access all spark functionality. In order to use APIs of SQL, HIVE,                                     and Streaming, separate contexts need to be created. From SPARK 2.0.0 onwards                         sparkSession provides a single point of entry to interact with underlying Spark                         functionality and allows programming Spark with Dataframe and Dataset APIs. All the                         functionality available with ​sparkContext​ are also available in ​sparkSession​.   \n",
    "\n",
    "Write the code to create a sparkSession object, with 4 local cores. To create a                               sparkSession with 4 core you have to use configure it as ​local[4]. Give a name to your                                   program using ​appName()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a spark context with 4 local cores.\n",
    "sc = SparkContext.getOrCreate()\n",
    "if (sc is None):\n",
    "    sc = SparkContext(master=\"local[4]\")\n",
    "\n",
    "# Name the program with appName()\n",
    "spark = SparkSession(sparkContext=sc)\\\n",
    "    .builder\\\n",
    "    .appName(\"Assignment 2\")\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 02: Load the dataset and print the schema and total number of entries\n",
    "In ​sparkSession you can use ​spark_session.read.csv() method to load data as CSV                         format. You can download the dataset from Moodle. After you load the csv file into a                                 dataframe using spark session, write the code to print the total number of entries in the                                 dataset.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 142193 entries in the dataset.\n"
     ]
    }
   ],
   "source": [
    "# Read the data and save in a dataframe.\n",
    "df = spark.read.csv(\"weatherAUS.csv\", header = True, inferSchema = True)\n",
    "total_lines = df.count()\n",
    "print((\"There are %d entries in the dataset.\"%total_lines))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer\n",
    "The total number of entries in the dataset is 142193."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  B. Data Cleaning and Processing  \n",
    "Data cleaning and processing is an important aspect for any machine learning task. We                             have to carefully look into the data and based on the types, quality of the data, we have                                     to plan our cleaning procedures.  \n",
    "\n",
    "\n",
    "### Step 03: Delete columns from the dataset   \n",
    "During the data cleaning and processing phase, we delete unnecessary data from                         the dataset to improve the efficiency and accuracy of our model. You have to think                               which columns are not contributing to the rain prediction. To keep things simple, you are                               required to delete the following columns due to data quality and accuracy. \n",
    "- Date  \n",
    "- Location  \n",
    "- Evaporation  \n",
    "- Sunshine  \n",
    "- Cloud9am  \n",
    "- Cloud3pm  \n",
    "- Temp9am  \n",
    "- Temp3pm    \n",
    "\n",
    "However, if you want to keep any of these columns, you can keep them if you process                                   them in an intelligent way that improve the accuracy, that is fine, ​however not                             mandatory​. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete irrelevant columns.\n",
    "df = df.drop(\"Date\",\"Location\",\"Evaporation\",\"Sunshine\",\"Cloud9am\",\"Cloud3pm\",\"Temp9am\",\"Temp3pm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 04: Print the number of missing data in each column\n",
    "We already have an initial idea about the data structure from the schema. Even in                               plain eyes, we can observe that there are lots of NA (null) values in the given dataset.                                   Your job in this step is to print the number of NA(null) values in each column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of null values for each column:\n",
      "('MinTemp', 637)\n",
      "('MaxTemp', 322)\n",
      "('Rainfall', 1406)\n",
      "('WindGustDir', 9330)\n",
      "('WindGustSpeed', 9270)\n",
      "('WindDir9am', 10013)\n",
      "('WindDir3pm', 3778)\n",
      "('WindSpeed9am', 1348)\n",
      "('WindSpeed3pm', 2630)\n",
      "('Humidity9am', 1774)\n",
      "('Humidity3pm', 3610)\n",
      "('Pressure9am', 14014)\n",
      "('Pressure3pm', 13981)\n",
      "('RainToday', 1406)\n",
      "('RainTomorrow', 0)\n"
     ]
    }
   ],
   "source": [
    "# Create a udf to filter the NA values.\n",
    "dropNa = udf(lambda x : not (x == \"NA\"), BooleanType())\n",
    "\n",
    "# An empty list to save results.\n",
    "null_count = []\n",
    "null_count.append(\"Number of null values for each column:\")\n",
    "\n",
    "# Calculate number of NA values for each column.\n",
    "for i in df.columns:\n",
    "    null_count.append((i, total_lines - df.filter(dropNa(i)).count()))\n",
    "    \n",
    "# Print the result.\n",
    "for i in null_count:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 05: Fill the missing data with average value and maximum occurrence value\n",
    "In this step you have to fill in all the missing data with average value (for numeric                                   column) or maximum frequency value (for non-numeric column).  \n",
    "\n",
    "Firstly, identify the columns which have numeric values (e.g., MinTemp, MaxTemp),                       calculate the average and fill the null value with the average.                              \n",
    "\n",
    "Secondly, identify the columns with non-numeric values (e.g., WindGustDir, WindDir9am)                     and find the for frequent item (e.g., wind direction). Now fill the null values with that item                                   for that particular column.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateAvg(column):\n",
    "    \"\"\"Calculate the average value for a numeric column.\n",
    "    \n",
    "    :param column: the name of the given column\n",
    "    :return: the average value\n",
    "    :rtype: float\n",
    "    \"\"\"\n",
    "    rdd = df.select(column).filter(dropNa(column)).rdd\n",
    "    return round(rdd.map(lambda x : float(x[0]))\\\n",
    "                 .reduce(lambda x, y : x+ y)/rdd.count(),2)\n",
    "\n",
    "def maxFrequency(column):\n",
    "    \"\"\"Find the max frquency item for a non-numeric column.\n",
    "    \n",
    "    :param column: the name of the given column\n",
    "    :return: the max frquency item\n",
    "    :rtype: String\n",
    "    \"\"\"\n",
    "    rdd = df.select(column).filter(dropNa(column)).rdd\n",
    "    text = rdd.map(lambda x : (x[0], 1))\\\n",
    "        .reduceByKey(lambda x,y : x + y)\\\n",
    "        .map(lambda x : (x[1], x[0]))\\\n",
    "        .sortByKey(ascending = False)\\\n",
    "        .collect()[0][1]\n",
    "    return text\n",
    "\n",
    "# Fill the NA values in each column\n",
    "df = df.replace(\"NA\",None)\\\n",
    "    .na.fill({\"MinTemp\": calculateAvg(\"MinTemp\")})\\\n",
    "    .na.fill({\"MaxTemp\": calculateAvg(\"MaxTemp\")})\\\n",
    "    .na.fill({\"Rainfall\": calculateAvg(\"Rainfall\")})\\\n",
    "    .na.fill({\"WindGustSpeed\": calculateAvg(\"WindGustSpeed\")})\\\n",
    "    .na.fill({\"WindSpeed9am\": calculateAvg(\"WindSpeed9am\")})\\\n",
    "    .na.fill({\"WindSpeed3pm\": calculateAvg(\"WindSpeed3pm\")})\\\n",
    "    .na.fill({\"Humidity9am\": calculateAvg(\"Humidity9am\")})\\\n",
    "    .na.fill({\"Humidity3pm\": calculateAvg(\"Humidity3pm\")})\\\n",
    "    .na.fill({\"Pressure9am\": calculateAvg(\"Pressure9am\")})\\\n",
    "    .na.fill({\"Pressure3pm\": calculateAvg(\"Pressure3pm\")})\\\n",
    "    .na.fill({\"WindGustDir\": maxFrequency(\"WindGustDir\")})\\\n",
    "    .na.fill({\"WindDir9am\": maxFrequency(\"WindDir9am\")})\\\n",
    "    .na.fill({\"WindDir3pm\": maxFrequency(\"WindDir3pm\")})\\\n",
    "    .na.fill({\"RainToday\": maxFrequency(\"RainToday\")})\\\n",
    "    .na.fill({\"RainTomorrow\": maxFrequency(\"RainTomorrow\")})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 06: Data transformation\n",
    "In this step, you have to transform the data so that it will be useful to process by                                     the machine learning algorithm. Before transforming your non-numerical data, do the                       type casting (to double) of the numerical value columns as they are defined as “String”                               (see, the schema of the dataset). For the non-numerical value column (i.e., WindGustDir,                           WindDir9am, WindDir3pm, RainTomorrow) use the StringIndexer method to convert                   them into numbers.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type casting to double\n",
    "df = df.withColumn(\"MinTemp\", df[\"MinTemp\"].cast(\"double\"))\\\n",
    "    .withColumn(\"MaxTemp\", df[\"MaxTemp\"].cast(\"double\"))\\\n",
    "    .withColumn(\"Rainfall\", df[\"Rainfall\"].cast(\"double\"))\\\n",
    "    .withColumn(\"WindGustSpeed\", df[\"WindGustSpeed\"].cast(\"double\"))\\\n",
    "    .withColumn(\"WindSpeed9am\", df[\"WindSpeed9am\"].cast(\"double\"))\\\n",
    "    .withColumn(\"WindSpeed3pm\", df[\"WindSpeed3pm\"].cast(\"double\"))\\\n",
    "    .withColumn(\"Humidity9am\", df[\"Humidity9am\"].cast(\"double\"))\\\n",
    "    .withColumn(\"Humidity3pm\", df[\"Humidity3pm\"].cast(\"double\"))\\\n",
    "    .withColumn(\"Pressure9am\", df[\"Pressure9am\"].cast(\"double\"))\\\n",
    "    .withColumn(\"Pressure3pm\", df[\"Pressure3pm\"].cast(\"double\"))\n",
    "\n",
    "# Convert Sting to numbers using StringIndexer\n",
    "strCols = [\"WindGustDir\", \"WindDir9am\", \"WindDir3pm\", \"RainToday\", \"RainTomorrow\"]\n",
    "df_index = df\n",
    "\n",
    "for i in strCols:\n",
    "    indexer = StringIndexer(inputCol = i, outputCol = i + \"Index\")\n",
    "    df_index = indexer.fit(df_index).transform(df_index)\n",
    "    \n",
    "df_index = df_index.drop(\"WindGustDir\", \"WindDir9am\", \"WindDir3pm\", \"RainToday\", \"RainTomorrow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 07: Create the feature vector and divide the dataset \n",
    "In this step, you have to create the feature vector from the given columns. When                               you create you feature vector, remember to exclude the column that you will be using                               for testing the accuracy of your model.     \n",
    "\n",
    "After creation of your feature vector, you have split your dataset into two (e.g., training                               and testing). In this assignment, you have to spit the dataset randomly and between 70                               percent and 30 percent.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform all features into a vector\n",
    "assembler = VectorAssembler(\n",
    "    inputCols = df_index.columns[:14], \n",
    "    outputCol = \"Features\")\n",
    "df_vector = assembler.transform(df_index).select(\"RainTomorrowIndex\", \"Features\")\n",
    "\n",
    "# Split the dataset randomly\n",
    "(train, test) = df_vector.randomSplit([0.7, 0.3], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C. Apply Machine Learning Algorithms \n",
    "### Step 08: Apply machine learning classification algorithms on the dataset and                       compare their accuracy. Plot the accuracy as bar graph.\n",
    "You have to use ​DecisionTreeClassifier(), RandomForestClassifier(), and               LogisticRegression(), GBTClassifier() methods in spark to calculate the probability of the                       rain fall tomorrow based on the other related data points (e.g., temperature, wind,                           humidity). Finally, you have to draw the graph (e.g. bar chart) to demonstrate the                             comparison of their accuracy.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "dt = DecisionTreeClassifier(\n",
    "    labelCol = \"RainTomorrowIndex\", \n",
    "    featuresCol = \"Features\")\n",
    "dt_model = dt.fit(train)\n",
    "\n",
    "# Predict\n",
    "dt_prediction = dt_model.transform(test)\n",
    "\n",
    "# Evaluate the accuracy\n",
    "dt_evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"RainTomorrowIndex\", \n",
    "    predictionCol=\"prediction\", \n",
    "    metricName=\"accuracy\")\n",
    "dt_accuracy = dt_evaluator.evaluate(dt_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "rf = RandomForestClassifier(\n",
    "    labelCol = \"RainTomorrowIndex\", \n",
    "    featuresCol = \"Features\")\n",
    "rf_model = rf.fit(train)\n",
    "\n",
    "# Predict\n",
    "rf_prediction = rf_model.transform(test)\n",
    "\n",
    "# Evaluate the accuracy\n",
    "rf_evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"RainTomorrowIndex\", \n",
    "    predictionCol=\"prediction\", \n",
    "    metricName=\"accuracy\")\n",
    "rf_accuracy = rf_evaluator.evaluate(rf_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regresstion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "lr = LogisticRegression(\n",
    "    labelCol = \"RainTomorrowIndex\", \n",
    "    featuresCol = \"Features\")\n",
    "lr_model = lr.fit(train)\n",
    "\n",
    "# Predict\n",
    "lr_prediction = lr_model.transform(test)\n",
    "\n",
    "# Evaluate the accuracy\n",
    "lr_evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"RainTomorrowIndex\", \n",
    "    predictionCol=\"prediction\", \n",
    "    metricName=\"accuracy\")\n",
    "lr_accuracy = lr_evaluator.evaluate(lr_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosted Trees(GBT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "gbt = GBTClassifier(\n",
    "    labelCol = \"RainTomorrowIndex\", \n",
    "    featuresCol = \"Features\")\n",
    "gbt_model = gbt.fit(train)\n",
    "\n",
    "# Predict\n",
    "gbt_prediction = gbt_model.transform(test)\n",
    "\n",
    "# Evaluate the accuracy\n",
    "gbt_evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"RainTomorrowIndex\", \n",
    "    predictionCol=\"prediction\", \n",
    "    metricName=\"accuracy\")\n",
    "gbt_accuracy = gbt_evaluator.evaluate(gbt_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfEAAAGDCAYAAAA72Cm3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3debwcZZ33/c/XRDZRUQk4JCEBQSFAEiTgcrvhgoA84DM6SAYVuEFGR1yQURkXdBgeFAT1GUUd3HAFgbmFqFFEhQE3SFiEYVMEhCBqkEVAlgR/9x9VJ3ROzklOIJ2TOvm8X69+naqrrq6+qqr7fLuuqq5KVSFJkrrncaPdAEmS9OgY4pIkdZQhLklSRxnikiR1lCEuSVJHGeKSJHWUIS6tRZJsmuSCJPckOXE1veZLkixY0+Y1zPzvTbLlcqbflOTl/Xp9aWWNH+0GSKtTkvOBGcDTq+rBUW7OaDgUuB14UnmRiGVU1YYDw0lOARZU1QdGr0XS8rknrrVGkqnAC4EC9l7Nr72mfGGeAlxtgC9tDdo+0koxxLU2eSPwS+AU4IDeCUnWT3Jikt8luTvJT5Os3057QZKfJ7kryS1JDmzLz09ySM88Dkzy057xSvLWJL8BftOW/f/tPP6S5JIkL+ypPy7J+5L8tu3uviTJ5CQnDe76TjInyeFDLWSS5yeZ1y7HvCTPb8sHlvs9bbfxMt3CSdZNckKSm5P8McnnetbDU5J8N8nCJHe2w5N6nvvUJF9O8vt2+lmD5n1Ekj8luS3JQcNtpCQHJbmmXQc3JPmn5dR9dpLL2rpnJPlWkmN6pr8pyfVJ7mjX2WY904baPpVkqySHAvv3rKvv9LzszCRXtOv3W0nWa5/7kiQLkrynZzlfnWTPJL9u2/C+4ZZFelSqyoePteIBXA/8M7ATsAjYtGfaScD5wERgHPB8YF2aPdd7gNnA44GnATPb55wPHNIzjwOBn/aMF3Au8FRg/bbs9e08xgNHAH8A1munvRu4EngWEJpu/6cBuwC/Bx7X1tsY+Gtv+3te86nAncAb2teY3Y4/rZ1+CnDMctbRJ4A57XyeCHwH+Eg77WnAa4AN2mlnAGf1PPd7wLeAp7Tr6sVt+UuAxcDRbfmebfufMkwbXgU8o10HL27rPrtnXgva4XWA3wHvaOf798BDA8sHvJTm0MGz2235KeCCFWyfArYabl0BNwEXA5u1z7sGePOg5Tyqbc+bgIXAN9v1tR1wP7DFaH8WfIydx6g3wIeP1fEAXkAT3Bu349cCh7fDj2v/uc4Y4nn/Cnx7mHmez4pD/KUraNedA68LXAfsM0y9a4BXtMOHAXOHqfcG4OJBZb8ADmyHlwmmnnoB7gOe0VP2PODGYerPBO5sh/8O+NtQwdyG2/3A+J6yPwHPHeG2Owt4R8+8BkL8RcCtQHrq/rQnxL8IHN8zbcP2PTB1uO0zwhB/fc/48cDnBi3nuHb8ie38ntNT/xLg1aP9efAxdh52p2ttcQDww6q6vR3/Jo90qW8MrAf8dojnTR6mfKRu6R1J8i9tV/HdSe4Cnty+/ope6ys0e/G0f782TL3NaPZOe/2OpodhRSbQ7GVf0h46uAv4QVtOkg2S/Gd7yOEvwAXARknGtW2/o6ruHGbef66qxT3jf6UJ1WUk2SPJL9vu57to9tw3HqLqZsCtVdV7fP+WQdOXrIuquhf4M0uvi6W2zwj9oWd48HL8uaoebofvb//+sWf6/Qyz3NKjYYhrzGuP6e4LvDjJH5L8ATgcmJFkBk2X6wM0XbiD3TJMOTR7rRv0jD99iDpLAqY9/v2eti1PqaqNgLtp9oBX9FpfB/Zp27stzd7pUH5Pcwig1+Y0e6wrcjtNyGxXVRu1jyfXI2dsH0HT1f+cqnoSzZ4wbftvAZ6aZKMRvM6wkqwL/BdwAs3hgo2AuTyyjnrdBkxM0jttcs/wUusiyRNoDgn0rovlneDnyX9a4xniWhu8GngYmEbTBTyTJggvBN5YVX8DvgR8PMlm7Qlmz2sD5RvAy5Psm2R8kqclmdnO93Lg79s91K2Ag1fQjifSHDNdCIxPchTwpJ7pXwD+PcnWaUxP8jSAqloAzKPZA/+vqrqfoc0FnpnkH9v2vq5d7u+uaCW16+HzwCeSbAKQZGKSV/a0/37griRPBT7U89zbgO8Dn2lPgHt8khex8tahOX69EFicZA9gt2Hq/oJmux7WLus+NOcPDDgVOCjJzHZbHgtcVFU3jbAtfwSG/c24tCYwxLU2OAD4clXdXFV/GHgAnwb2T/Pzon+hOalsHnAHcBzNiWQ303TnHtGWX05zwhk0J4E9RPPP/is0gb8859B0T/+appv3AZbuzv04cDrwQ+AvNMd01++Z/hVgB4bvSqeq/gzs1bb3zzR7/nv1HEZYkffSnAD4y7bL/Ec0e98An2zbczvNWf4/GPTcN9Acc76W5pj3O0f4mr3tvwd4O816uBP4R5oT7Yaq+xDNyWwHA3fRHGb4LvBgO/1HwAdp9uxvo+nl2G8lmvNFYFp7aGG4ng9pVGXpw0mS1lTtnu3XgSnlB3dISS6iOdHsy6PdFml1cE9c6oAkj6f5KdUXDPBHJHlxkqe33ekHANNZtodAGrO8SpG0hkuyLTAf+BUw7EVS1lLPoul6fwJwA/Da9vi8tFawO12SpI6yO12SpI4yxCVJ6qjOHRPfeOONa+rUqaPdDEmSVotLLrnk9qqaMNS0zoX41KlTmT9//mg3Q5Kk1SLJ4EspL2F3uiRJHWWIS5LUUYa4JKnvfvCDH/CsZz2Lrbbaio9+9KPLTL/55pvZdddd2XHHHZk+fTpz585dZvqGG27ICSecAMADDzzALrvswowZM9huu+340IeWXMqfF77whcycOZOZM2ey2Wab8epXv7q/CzeKOndMXJLULQ8//DBvfetbOffcc5k0aRI777wze++9N9OmTVtS55hjjmHfffflLW95C1dffTV77rknN91005Lp73rXu9hjjz2WjK+77rr85Cc/YcMNN2TRokW84AUvYI899uC5z30uF1544ZJ6r3nNa9hnn31Wy3KOBvfEJUl9dfHFF7PVVlux5ZZbss4667Dffvtx9tlnL1UnCX/5y18AuPvuu9lss82WTDvrrLPYYost2G677Zaqv+GGzV1yFy1axKJFi1j6rrTwl7/8hZ/85Cdjek/cEF9NHm1X0sUXX7ykW2jGjBl8+9vfXvKcqVOnssMOOzBz5kxmzZq1zDxPPPFEknD77SO9gZWgP9sKmr2RHXfckb322mtJ2YEHHsgWW2yx5HmXX355fxdujOnHtrrrrrt47WtfyzbbbMO2227LL37xCwBe97rXLXnO1KlTmTlz5jKvp6HdeuutTJ78yK3eJ02axK23Ln2L+w9/+MN8/etfZ9KkSey555586lOfAuDee+/luOOOW6q7fMDDDz/MzJkz2WSTTXjFK17Bc57znKWmn3XWWbzsZS/jSU960jLPHTOqqlOPnXbaqbpm8eLFteWWW9Zvf/vbevDBB2v69Ol11VVXLVXnTW96U33mM5+pqqqrrrqqpkyZUlVV9913Xy1atKiqqn7/+9/XhAkTloxPmTKlFi5cOORr3nzzzbXbbrvV5ptvPmwdLatf26qq6sQTT6zZs2fXq171qiVlBxxwQJ1xxhl9XqqxqV/b6o1vfGN9/vOfr6qqBx98sO68885lXvtd73pX/du//Vu/Fm3MOeOMM+rggw9eMv7Vr3613vrWty5V58QTT6wTTjihqqp+/vOf17bbblsPP/xwHXHEEfWtb32rqqo+9KEP1cc+9rFl5n/nnXfWS17ykrryyiuXKt99993rzDPPXNWLs9oB82uYTHRPfDV4LF1JG2ywAePHN6cuPPDAA8t0Fw3n8MMP5/jjjx9xfTX6ta0WLFjA9773PQ455JDVtCRjXz+21d13380FF1zAwQcfDMA666zDRhtttNQ8q4rTTz+d2bNn93X5xpKJEydyyy23LBlfsGABEydOXKrOF7/4Rfbdd18Anve85/HAAw9w++23c9FFF/Ge97yHqVOn8slPfpJjjz2WT3/600s9d6ONNmLXXXflBz945AZ2t99+OxdffDGvetWr+rhko88QXw0eS1cSwEUXXcR2223HDjvswOc+97kl/3ySsNtuu7HTTjtx8sknL6l/9tlnM3HiRGbMmNHnJRt7+rWt3vnOd3L88cfzuMct+5F7//vfz/Tp0zn88MN58MEH+7RkY08/ttWNN97IhAkTOOigg9hxxx055JBDuO+++5aa54UXXsimm27K1ltv3d8FHEN23nlnfvOb33DjjTfy0EMPcdppp7H33nsvVWfzzTfnxz/+MQDXXHMNDzzwABMmTODCCy/kpptu4qabbuKd73wn73vf+zjssMNYuHAhd911FwD3338/5557Lttss82S+Z155pnstdderLfeeqtvQUeBIb6GOPXUUznwwANZsGABc+fO5Q1veAN/+9vfAHjOc57DVVddxbx58/jIRz7CAw88AMBPf/pTLr30Ur7//e9z0kknccEFF/DXv/6VY489lqOPPno0F2dMW9lt9d3vfpdNNtmEnXbaaZl5feQjH+Haa69l3rx53HHHHRx33HGre3HGtJXdVosXL+bSSy/lLW95C5dddhlPeMITljnWfuqpp7oXvpLGjx/Ppz/9aV75yley7bbbsu+++7Lddttx1FFHMWfOHKA5h+fzn/88M2bMYPbs2ZxyyinL7Um87bbb2HXXXZk+fTo777wzr3jFK5Y63+S0005bO7bTcP3sa+qji8fEf/7zn9duu+22ZPzYY4+tY489dqk606ZNq5tvvnnJ+BZbbFF//OMfl5nXrrvuWvPmzVumfOBY0RVXXFETJkyoKVOm1JQpU2rcuHE1efLkuu2221bhEo1d/dhWRx55ZE2cOLGmTJlSm266aa2//vq1//77L1P/vPPOW+p4uZavH9vqtttuW3LcvKrqggsuqD333HPJ+KJFi2qTTTapW265ZRUuibR8eEx8dD2WrqQbb7yRxYsXA/C73/2Oa6+9lqlTp3Lfffdxzz33AHDffffxwx/+kO23354ddtiBP/3pT0u6nyZNmsSll17K05/+9NW70B3Vj231kY98hAULFnDTTTdx2mmn8dKXvpSvf/3rQLM3Ac2X6bPOOovtt99+NS5tt/VjWz396U9n8uTJXHfddQD8+Mc/Xuq3zD/60Y/YZpttmDRp0mpaSmkFhkv3NfXRxT3xqqrvfe97tfXWW9eWW25ZxxxzTFVVffCDH6yzzz67qpozZ5///OfX9OnTa8aMGXXOOedUVXMW57Rp02rGjBm144471re//e2qqvrtb39b06dPr+nTp9e0adOWzHOw5Z3BrqGt6m3Va/De9q677lrbb799bbfddrX//vvXPffcsxqWcOzox7a67LLLaqeddqoddtih9tlnn7rjjjuWTDvggAPqs5/97GpcQmn5e+JppnfHrFmzyruYSdKqMfXI7412E8acmz66as+IT3JJVS17MRA8sU2SpM4yxCVJ6qi1/gYodiX1x6ruTlK3+Lla9fxMaShrfYirOwyG/jAcpO6yO12SpI4yxCVJ6ihDXJKkjjLEJUnqKENckqSOMsQlSeooQ1ySpI4yxCVJ6qi+hniS3ZNcl+T6JEcOMX3zJOcluSzJFUn27Gd7JEkaS/oW4knGAScBewDTgNlJpg2q9gHg9KraEdgP+Ey/2iNJ0ljTzz3xXYDrq+qGqnoIOA3YZ1CdAp7UDj8Z+H0f2yNJ0pjSzxCfCNzSM76gLev1YeD1SRYAc4G3DTWjJIcmmZ9k/sKFC/vRVkmSOme0T2ybDZxSVZOAPYGvJVmmTVV1clXNqqpZEyZMWO2NlCRpTdTPEL8VmNwzPqkt63UwcDpAVf0CWA/YuI9tkiRpzOhniM8Dtk6yRZJ1aE5cmzOozs3AywCSbEsT4vaXS5I0An0L8apaDBwGnANcQ3MW+lVJjk6yd1vtCOBNSX4FnAocWFXVrzZJkjSWjO/nzKtqLs0Ja71lR/UMXw38r362QZKksWq0T2yTJEmPkiEuSVJHGeKSJHWUIS5JUkcZ4pIkdZQhLklSRxnikiR1lCEuSVJHGeKSJHWUIS5JUkcZ4pIkdZQhLklSRxnikiR1lCEuSVJHGeKSJHWUIS5JUkcZ4pIkdZQhLklSRxnikiR1lCEuSVJHGeKSJHWUIS5JUkcZ4pIkdZQhLklSRxnikiR1lCEuSVJHGeKSJHWUIS5JUkf1NcST7J7kuiTXJzlyiOmfSHJ5+/h1krv62R5JksaS8f2acZJxwEnAK4AFwLwkc6rq6oE6VXV4T/23ATv2qz2SJI01/dwT3wW4vqpuqKqHgNOAfZZTfzZwah/bI0nSmNLPEJ8I3NIzvqAtW0aSKcAWwE+GmX5okvlJ5i9cuHCVN1SSpC5aU05s2w84s6oeHmpiVZ1cVbOqataECRNWc9MkSVoz9TPEbwUm94xPasuGsh92pUuStFL6GeLzgK2TbJFkHZqgnjO4UpJtgKcAv+hjWyRJGnP6FuJVtRg4DDgHuAY4vaquSnJ0kr17qu4HnFZV1a+2SJI0FvXtJ2YAVTUXmDuo7KhB4x/uZxskSRqr1pQT2yRJ0koyxCVJ6ihDXJKkjjLEJUnqKENckqSOMsQlSeooQ1ySpI4yxCVJ6ihDXJKkjjLEJUnqKENckqSOMsQlSeooQ1ySpI4yxCVJ6ihDXJKkjjLEJUnqKENckqSOMsQlSeooQ1ySpI4yxCVJ6ihDXJKkjjLEJUnqKENckqSOMsQlSeooQ1ySpI4yxCVJ6ihDXJKkjupriCfZPcl1Sa5PcuQwdfZNcnWSq5J8s5/tkSRpLBnfrxknGQecBLwCWADMSzKnqq7uqbM18K/A/6qqO5Ns0q/2SJI01vRzT3wX4PqquqGqHgJOA/YZVOdNwElVdSdAVf2pj+2RJGlM6WeITwRu6Rlf0Jb1eibwzCQ/S/LLJLv3sT2SJI0pfetOX4nX3xp4CTAJuCDJDlV1V2+lJIcChwJsvvnmq7uNkiStkfq5J34rMLlnfFJb1msBMKeqFlXVjcCvaUJ9KVV1clXNqqpZEyZM6FuDJUnqkn6G+Dxg6yRbJFkH2A+YM6jOWTR74STZmKZ7/YY+tkmSpDGjbyFeVYuBw4BzgGuA06vqqiRHJ9m7rXYO8OckVwPnAe+uqj/3q02SJI0lfT0mXlVzgbmDyo7qGS7gXe1DkiStBK/YJklSRxnikiR1lCEuSVJHGeKSJHWUIS5JUkcZ4pIkdZQhLklSRxnikiR1lCEuSVJHGeKSJHWUIS5JUkcZ4pIkdZQhLklSRxnikiR1lCEuSVJHGeKSJHWUIS5JUkcZ4pIkdZQhLklSRxnikiR1lCEuSVJHGeKSJHWUIS5JUkcZ4pIkdZQhLklSRxnikiR1lCEuSVJHGeKSJHVUX0M8ye5JrktyfZIjh5h+YJKFSS5vH4f0sz2SJI0l4/s14yTjgJOAVwALgHlJ5lTV1YOqfquqDutXOyRJGqv6uSe+C3B9Vd1QVQ8BpwH79PH1JElaq/QzxCcCt/SML2jLBntNkiuSnJlkch/bI0nSmLLCEE/ytiRP6dPrfweYWlXTgXOBrwzThkOTzE8yf+HChX1qiiRJ3TKSPfFNaY5nn96eqJYRzvtWoHfPelJbtkRV/bmqHmxHvwDsNNSMqurkqppVVbMmTJgwwpeXJGlsW2GIV9UHgK2BLwIHAr9JcmySZ6zgqfOArZNskWQdYD9gTm+FJH/XM7o3cM1KtF2SpLXaiI6JV1UBf2gfi4GnAGcmOX45z1kMHAacQxPOp1fVVUmOTrJ3W+3tSa5K8ivg7TRfEiRJ0gis8CdmSd4BvBG4nabL+91VtSjJ44DfAO8Z7rlVNReYO6jsqJ7hfwX+9dE1XZKktdtIfif+VODvq+p3vYVV9bcke/WnWZIkaUVG0p3+feCOgZEkT0ryHICq8hi2JEmjZCQh/lng3p7xe9sySZI0ikYS4mlPbAOabnT6eLlWSZI0MiMJ8RuSvD3J49vHO4Ab+t0wSZK0fCMJ8TcDz6e5UMsC4DnAof1slCRJWrEVdotX1Z9oLtQiSZLWICP5nfh6wMHAdsB6A+VV9b/72C5JkrQCI+lO/xrwdOCVwH/TXAP9nn42SpIkrdhIQnyrqvogcF9VfQV4Fc1xcUmSNIpGEuKL2r93JdkeeDKwSf+aJEmSRmIkv/c+ub2f+Ado7kK2IfDBvrZKkiSt0HJDvL3JyV+q6k7gAmDL1dIqSZK0QsvtTm+vzjbsXcokSdLoGckx8R8l+Zckk5M8deDR95ZJkqTlGskx8de1f9/aU1bYtS5J0qgayRXbtlgdDZEkSStnJFdse+NQ5VX11VXfHEmSNFIj6U7fuWd4PeBlwKWAIS5J0igaSXf623rHk2wEnNa3FkmSpBEZydnpg90HeJxckqRRNpJj4t+hORsdmtCfBpzez0ZJkqQVG8kx8RN6hhcDv6uqBX1qjyRJGqGRhPjNwG1V9QBAkvWTTK2qm/raMkmStFwjOSZ+BvC3nvGH2zJJkjSKRhLi46vqoYGRdnid/jVJkiSNxEhCfGGSvQdGkuwD3N6/JkmSpJEYyTHxNwPfSPLpdnwBMORV3CRJ0uqzwj3xqvptVT2X5qdl06rq+VV1/UhmnmT3JNcluT7Jkcup95oklWTWyJsuSdLabYUhnuTYJBtV1b1VdW+SpyQ5ZgTPGwecBOxB8wVgdpJpQ9R7IvAO4KKVb74kSWuvkRwT36Oq7hoYqao7gT1H8LxdgOur6ob2ZLjTgH2GqPfvwHHAAyOYpyRJao0kxMclWXdgJMn6wLrLqT9gInBLz/iCtmyJJM8GJlfV90YwP0mS1GMkJ7Z9A/hxki8DAQ4EvvJYXzjJ44CPt/NbUd1DgUMBNt9888f60pIkjQkjObHtOOAYYFvgWcA5wJQRzPtWYHLP+KS2bMATge2B85PcBDwXmDPUyW1VdXJVzaqqWRMmTBjBS0uSNPaN9C5mf6S5Cco/AC8FrhnBc+YBWyfZIsk6wH7AnIGJVXV3VW1cVVOrairwS2Dvqpq/MgsgSdLaatju9CTPBGa3j9uBbwGpql1HMuOqWpzkMJo993HAl6rqqiRHA/Oras7y5yBJkpZnecfErwUuBPYa+F14ksNXZuZVNReYO6jsqGHqvmRl5i1J0tpued3pfw/cBpyX5PNJXkZzYpskSVoDDBviVXVWVe0HbAOcB7wT2CTJZ5PstroaKEmShjaSs9Pvq6pvVtX/Q3OG+WXAe/veMkmStFwjPTsdaK7W1v7c62X9apAkSRqZlQpxSZK05jDEJUnqKENckqSOMsQlSeooQ1ySpI4yxCVJ6ihDXJKkjjLEJUnqKENckqSOMsQlSeooQ1ySpI4yxCVJ6ihDXJKkjjLEJUnqKENckqSOMsQlSeooQ1ySpI4yxCVJ6ihDXJKkjjLEJUnqKENckqSOMsQlSeooQ1ySpI4yxCVJ6qi+hniS3ZNcl+T6JEcOMf3NSa5McnmSnyaZ1s/2SJI0lvQtxJOMA04C9gCmAbOHCOlvVtUOVTUTOB74eL/aI0nSWNPPPfFdgOur6oaqegg4Ddint0JV/aVn9AlA9bE9kiSNKeP7OO+JwC094wuA5wyulOStwLuAdYCXDjWjJIcChwJsvvnmq7yhkiR10aif2FZVJ1XVM4D3Ah8Yps7JVTWrqmZNmDBh9TZQkqQ1VD9D/FZgcs/4pLZsOKcBr+5jeyRJGlP6GeLzgK2TbJFkHWA/YE5vhSRb94y+CvhNH9sjSdKY0rdj4lW1OMlhwDnAOOBLVXVVkqOB+VU1BzgsycuBRcCdwAH9ao8kSWNNP09so6rmAnMHlR3VM/yOfr6+JElj2aif2CZJkh4dQ1ySpI4yxCVJ6ihDXJKkjjLEJUnqKENckqSOMsQlSeooQ1ySpI4yxCVJ6ihDXJKkjjLEJUnqKENckqSOMsQlSeooQ1ySpI4yxCVJ6ihDXJKkjjLEJUnqKENckqSOMsQlSeooQ1ySpI4yxCVJ6ihDXJKkjjLEJUnqKENckqSOMsQlSeooQ1ySpI4yxCVJ6ihDXJKkjupriCfZPcl1Sa5PcuQQ09+V5OokVyT5cZIp/WyPJEljSd9CPMk44CRgD2AaMDvJtEHVLgNmVdV04Ezg+H61R5Kksaafe+K7ANdX1Q1V9RBwGrBPb4WqOq+q/tqO/hKY1Mf2SJI0pvQzxCcCt/SML2jLhnMw8P2hJiQ5NMn8JPMXLly4CpsoSVJ3rREntiV5PTAL+NhQ06vq5KqaVVWzJkyYsHobJ0nSGmp8H+d9KzC5Z3xSW7aUJC8H3g+8uKoe7GN7JEkaU/q5Jz4P2DrJFknWAfYD5vRWSLIj8J/A3lX1pz62RZKkMadvIV5Vi4HDgHOAa4DTq+qqJEcn2but9jFgQ+CMJJcnmTPM7CRJ0iD97E6nquYCcweVHdUz/PJ+vr4kSWPZGnFimyRJWnmGuCRJHWWIS5LUUYa4JEkdZYhLktRRhrgkSR1liEuS1FGGuCRJHWWIS5LUUYa4JEkdZYhLktRRhrgkSR1liEuS1FGGuCRJHWWIS5LUUYa4JEkdZYhLktRRhrgkSR1liEuS1FGGuCRJHWWIS5LUUYa4JEkdZYhLktRRhrgkSR1liEuS1FGGuCRJHWWIS5LUUYa4JEkd1dcQT7J7kuuSXJ/kyCGmvyjJpUkWJ3ltP9siSdJY07cQTzIOOAnYA5gGzE4ybVC1m4EDgW/2qx2SJI1V4/s4712A66vqBoAkpwH7AFcPVKiqm9ppf+tjOyRJGpP62Z0+EbilZ3xBW7bSkhyaZH6S+QsXLlwljZMkqes6cWJbVZ1cVbOqataECRNGuzmSJK0R+hnitwKTe8YntWWSJGkV6GeIzwO2TrJFknWA/YA5fXw9SZLWKn0L8apaDBwGnANcA5xeVVclOTrJ3gBJdk6yAPgH4D+TXNWv9kiSNNb08+x0qmouMHdQ2VE9w/NoutklSdJK6sSJbZIkaVmGuCRJHWWIS5LUUYa4JEkdZYhLktRRhrgkSR1liEuS1FGGuCRJHWWIS5LUUSnDSoYAAA20SURBVIa4JEkdZYhLktRRhrgkSR1liEuS1FGGuCRJHWWIS5LUUYa4JEkdZYhLktRRhrgkSR1liEuS1FGGuCRJHWWIS5LUUYa4JEkdZYhLktRRhrgkSR1liEuS1FGGuCRJHWWIS5LUUX0N8SS7J7kuyfVJjhxi+rpJvtVOvyjJ1H62R5KksaRvIZ5kHHASsAcwDZidZNqgagcDd1bVVsAngOP61R5Jksaafu6J7wJcX1U3VNVDwGnAPoPq7AN8pR0+E3hZkvSxTZIkjRn9DPGJwC094wvasiHrVNVi4G7gaX1skyRJY8b40W7ASCQ5FDi0Hb03yXWj2Z5RtDFw+2g3YiTigRG3VXd0Ylu5nbqxnaAv22rKcBP6GeK3ApN7xie1ZUPVWZBkPPBk4M+DZ1RVJwMn96mdnZFkflXNGu12aMXcVt3htuoGt9PQ+tmdPg/YOskWSdYB9gPmDKozBzigHX4t8JOqqj62SZKkMaNve+JVtTjJYcA5wDjgS1V1VZKjgflVNQf4IvC1JNcDd9AEvSRJGoG+HhOvqrnA3EFlR/UMPwD8Qz/bMMas9YcUOsRt1R1uq25wOw0h9l5LktRNXnZVkqSOMsRXUpKHk1ye5Kokv0pyRJJHtR6THJ3k5cuZ/uYkb3wU831l28bLk9zbXvr28iRffTTt7IqebfM/Sb6TZKNVNN+pSf5nFc3rlCQ39myft6+K+Q7zWi9J8vx+zX+I17t3FcxjsyRnLmf6Rkn+eaT12zrnt5+BXyWZl2TmY23nqrSi/wNriySbJvlmkhuSXJLkF0n+3/Z9fHf7ebkiyY+SbJLkoJ7P0UNJrmyHPzray7I62Z2+kpLcW1UbtsObAN8EflZVHxrdlg0tyfnAv1TV/CGmjW8vsjMmDNo2XwF+XVX/3yqY71Tgu1W1/SqY1yntvJYbPMM8d1xVPbwS9T8M3FtVJ6zsaz0aveu/j68xlZXcFr2fgSQHAf9YVa9YBW0ZU5+f0dReqfPnwFeq6nNt2RRgb+BKmu23V1v+EeCh3v+5SW4CZlVVJ35Hviq5J/4YVNWfaC5Cc1ga45J8rP22f0WSfxqom+S97TfFXw18U2z3yl7bDn80ydXt805oyz6c5F/a4ZlJftlO/3aSp7Tl5yc5LsnFSX6d5IXLa3OSQ5KcleQ8ml8OkOTI9vlXJDmqp+4BbfnlST7zaHscRskvaK8QmGTDJD9Ocmm7DfZpy6cmuSbJ59P0rPwwyfrttJ3abfUr4K0DM02yXpIvt/O5LMmubfmB7Xo9N8lNSQ5L8q62zi+TPHV5jU0yu53n/ySPXCoiTU/KiW07nte267/bPZVzkvxdW+/tPe+f09qwezNweLv9lvu+6Jd2Hf+kbdePk2zelj+jXS9XJjkm7V58eno9kmzX8/67IsnWwEeBZ7RlHxtUf1ySE9p1eEWStw3RpCXvi/Y5u6XZ47s0yRlJBr4E7pnk2nY9/0eS77blH07ytSQ/o/llzZCf+SR/l+SCPNIz9MK27int+JVJDm/r9v4feFn7nrkyyZeSrNuW35Tk33rew9v0YXONppfSBPPnBgqq6ndV9aneSkkCPBG4czW3b81VVT5W4kGzZzO47C5gU5pA/0Bbti4wH9iC5iYwPwc2aKc9tf17Cs3v458GXMcjPSMbtX8/TPMNFOAK4MXt8NHAJ9vh84ET2+E9gR8Natv5NN9QB8YPAX4HPKXnOZ8BQvOl7gfA84HtgbOA8W29k2n2YEZ9G6xo29D8pPEMYPd2fDzwpHZ4Y+D6dnmnAouBme2004HX96zvF7XDHwP+px0+gubnkgDbADcD6wEHtvN9IjCB5hLCb27rfQJ4Z882vxG4vH3sAGzWzmdC29afAK9u6xewbzv8+PZ9NKEdf11PW34PrDvc+2cUPxvfAQ5oh/83cFY7/F1gdjv85p5tN7VnXX8K2L8dXgdYv3f6EPXfQnMPhoH37MDn7HzazwDwTuDYnvfCBcAT2vH3Ake12/MWYIu2/FSavf+BdXoJsH47Ptxn/gjg/T3vxycCOwHn9rR9YDudQvN/YOB1n9mWf7XnfXMT8LZ2+J+BL4z2520Vv3feDnximGkvofk8Xd6un2tpP889dW4CNh7t5RiNR5f2rLpgN+CNSS4HLqIJ562BlwNfrqq/AlTVHYOedzfwAPDFJH8P/LV3YpIn03zg/7st+grwop4q/6f9ewnNP7UV+WFVDXyT3Y3mS8ZlwKXAVsAz2zbvDMxvl+fFwDNGMO/RtH7b1j/QfKk6ty0PcGySK4Af0eyJbdpOu7GqLm+HLwGmpjmWvlFVXdCWf63nNV4AfB2gqq6l+UL0zHbaeVV1T1UtpNmm32nLr2Tp7fLuqprZPq6kWc/nV9XCarpnv8Ej2/dh4L/a4WfRfLk6t13OD9BcCRGaLx3fSPJ6mi8ma4rn0RxygmY9vqCn/Ix2+JuDn9T6BfC+JO8FplTV/St4rZcD/9muw8Gfs28kuRF4P83dFQGeS3OHxZ+16/MAmstbbgPcUFU3tvVOHfQ6c3raMtxnfh5wUJpDGjtU1T3ADcCWST6VZHfgL4Pm+yya9+Ov2/HH+jnvrCQntT1h89qiC9vPy2Tgy8Dxo9i8NYoh/hgl2ZLmH+2faMLibT3/oLeoqh+uaB7tP51daPYi9qLZG14ZD7Z/H2Zkv/2/r2c4wDE9bd6qqk5py7/UU/6sqvr3lWzX6nZ/Vc2k+UccHukG359mL3endvofafZ64JF1ByNff8Ppndffesb/9hjm+0A9chw8wFU922SHqtqtnfYqmnB6NjAvzWWMO62qvklzTPR+YG6Slz6G2e0PbEkTjANdtKHZMx5Yn9Oq6uARzGvw52eZz3z7BfBFNJeWPiXJG9svzjNoegbeDHxhJZdhZT/nXXIVzXsXgKp6K/Ayms/tYHNY+svNWs0QfwySTAA+B3y6mj6dc4C3JHl8O/2ZSZ5As0d4UJIN2vKnDprPhsCTq7k4zuE0H/Qlqupu4M6e45pvAP6bVeMc4OC2nSSZlGRjmj3Wfdthkjxt4Hjmmq7t8Xg7cEQeuSb/n6pqUZpj2MPeTKB9/l3AXUkG9hr375l84cB4kmcCm9McCnksLgZenGTjJOOA2Qy9fa8DJiR5Xvv6j2+PGz8OmFxV59F0CT8Z2BC4h6YbdzT9nEeuxLg/zfoD+CXwmnZ4yCs1tl+Qb6iq/wDOBqaz/GU6F/ingS8wgz9n7Wf0g8Bz22PKvwT+V5Kt2vpPaLfpdTR7zFPbp75uOcs35Gc+zUlZf6yqz9OE9bPbz9Ljquq/aHpRnj1oXtfR9ARt1Y6vys/5mu4nwHpJ3tJTtsEwdV8A/Lb/TeqGsfZtbnUY6LJ9PE235deAj7fTvkDTzXVpewLGQppjmz9I87OW+UkeormK3ft65vlE4Owk69F8s3/XEK97APC59ovADcBBq2JhqmruwD+0psncQ3Ps+8ok/wb8qA2JRTR7Dzevitftt6q6rO0+n03TPf2dJFfSHLO8dgSzOAj4UpICentTPgN8tp3XYuDAqnqwXXePtq23JTkSOI9m+3+vqs4eot5D7QlQ/9EeYhkPfBL4NfD1tizAf1TVXUm+A5yZ5kS+t1XVhYPnuYptkGRBz/jHgbcBX07ybprPw8D79p1tm99P0/N09xDz2xd4Q5JFNIdIjq2qO5L8LM3JbN/nka5xaD5/zwSuaJ/zeeDTvTOsqvuTnEhzSOPgJAcCpw6cQEZzfPvXaX7G9oMk99F0jQ9nyM88zXHcd7ftuBd4I81hnC/nkRNE/3VQ2x5Ic/b8Ge0XkXk0OwljXlVVklcDn0jyHpr1eB/Nl1KAF7b/d0PzXjlkdFq65vEnZpJWu/bL6P3tP+/9aE5y22e02zUgyYZVdW8bzCcBv6mqT4x2u6TB3BOXNBp2Aj7dhuRdNGeur0nelOQAmrPiLwP+c5TbIw3JPXFJkjrKE9skSeooQ1ySpI4yxCVJ6ihDXBpjkrw6SQ1cXzur8C5s7fy+kGRaO/y+nvJV+jqSVswQl8ae2cBP27+rVJo7qR1SVVe3Re9b7hMk9ZUhLo0h7dX/XgAczBBXQkuyQZLT09zx7NtJLkoyq5020jupnZ9kVpq78a2f5k5d32irj8vQd4U7P8knksxPc+e4nZP8nyS/SXJMv9eLNFYZ4tLYsg/wg/YmGn9OstOg6f8M3FlV02guQboTQJLNgONobgk5E9i5vYIWwBOAi6pqRlX9dGBGVXUk7fXqq2rg0rRbAydV1XY0v/8euLQqNLeanEVzFbKzaa5tvz1wYJKnraLll9Yqhrg0tswGTmuHT2PZLvUXDEyvqv+hufsZjPxOaiuyzF3heqbNaf9eSXMjl9uq6kGaywhPHuH8JfXwim3SGNHe8OOlwA7tNd/H0dyP/KTlPnHFeu+ktiKD7wq3/hDT/sayd3zzf5H0KLgnLo0drwW+VlVTqmpqe+/lG1l6L/dnNDcWoT3DfIe2fKR3Uhts0cAdvCStfoa4NHbMBr49qOy/WPpuWZ+huZ3p1cAxNPdxvruqbgMG7qT2K+CSoe6kNoSTae4a9o0V1pS0ynntdGkt0u5lP7697eUzaO4b/6yqemiUmybpUfA4lLR22QA4r+0CD/DPBrjUXe6JS5LUUR4TlySpowxxSZI6yhCXJKmjDHFJkjrKEJckqaMMcUmSOur/AlUDXBU1/uT2AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create x-axis and y-axis\n",
    "x = [\"DecisionTree\", \"RandomForest\", \"LogisticRegression\", \"GBT\"]\n",
    "y = [dt_accuracy, rf_accuracy, lr_accuracy, gbt_accuracy]\n",
    "\n",
    "# Create a bar chart\n",
    "fig, ax = pyplot.subplots() \n",
    "accuracy_bars = ax.bar(x, y)\n",
    "\n",
    "# Add values on the top of bars\n",
    "for bar in accuracy_bars:\n",
    "    ax.text(bar.get_x() + bar.get_width()/3.5, bar.get_height() + 0.01, \"%.4f\"%bar.get_height())\n",
    "\n",
    "# Set labels and size\n",
    "ax.set_title('Accuracy of each algorithm')\n",
    "ax.set_xlabel(\"Algorithm\")\n",
    "ax.set_ylabel(\"Accuracy\")\n",
    "fig.set_size_inches(8,6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 09: Calculate the confusion matrix and find the precision, recall, and F1                           score of each classification algorithm. Explain how the accuracy of the                       predication can be improved?\n",
    "Finding the accuracy of the model does not always represent the quality of the                             model for a given dataset. Number of false positive and false negative identification also                             plays an important role when we decide about any particular classification model. The                           way we can calculate is called confusion matrix. You can use confusionMatrix() method                           to calculate the confusion matrix. From the confusion matrix show the precision, recall                           and f1 score of each classification model. Explain how you can improve the accuracy of                               the predication.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[31344.  1629.]\n",
      " [ 5362.  4143.]]\n",
      "\n",
      "Rain tomorrow?       No                Yes      \n",
      "Precision:  0.8539203399989103 0.7177754677754677\n",
      "Recall:     0.9505959421344736 0.4358758548132562\n",
      "F1 score:   0.8996684797428207 0.5423839759115009\n"
     ]
    }
   ],
   "source": [
    "# Calculate the confusion matrix\n",
    "dt_rdd = dt_prediction.select(\"prediction\", \"RainTomorrowIndex\").rdd\n",
    "dt_metrics = MulticlassMetrics(dt_rdd)\n",
    "dt_cm = dt_metrics.confusionMatrix().toArray()\n",
    "\n",
    "# Calculate the precision, recall and f1-score for \"No\" and \"Yes\".\n",
    "dt_precision_0 = dt_metrics.precision(0)\n",
    "dt_recall_0 = dt_metrics.recall(0)\n",
    "dt_f1_0 = dt_metrics.fMeasure(0.0)\n",
    "dt_precision_1 = dt_metrics.precision(1)\n",
    "dt_recall_1 = dt_metrics.recall(1)\n",
    "dt_f1_1 = dt_metrics.fMeasure(1.0)\n",
    "\n",
    "# Print the result\n",
    "print(\"Confusion Matrix:\\n\",dt_cm)\n",
    "print(\"\\nRain tomorrow?\", \"      No       \", \"        Yes      \")\n",
    "print(\"Precision: \", dt_precision_0, dt_precision_1)\n",
    "print(\"Recall:    \", dt_recall_0, dt_recall_1)\n",
    "print(\"F1 score:  \", dt_f1_0, dt_f1_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: In this confusion matrix, the positive value represents \"No rain\", and the negative value represents \"Rain tomorrow\". The rows represents the prediction, and the columns represents real condition.\n",
    "\n",
    "|Confusion Matrix|Condition Positive|Condition Negative|\n",
    "|---|---|---|\n",
    "|Prediction Positive|True Positive|False Positive|\n",
    "|Prediction Negative|False Negative|True Negative|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[31745.  1228.]\n",
      " [ 5800.  3705.]]\n",
      "\n",
      "Rain tomorrow?       No                Yes      \n",
      "Precision:  0.845518710880277 0.7510642610987229\n",
      "Recall:     0.9627574075758955 0.38979484481851656\n",
      "F1 score:   0.9003375024816359 0.5132289790829755\n"
     ]
    }
   ],
   "source": [
    "# Calculate the confusion matrix\n",
    "rf_rdd = rf_prediction.select(\"prediction\", \"RainTomorrowIndex\").rdd\n",
    "rf_metrics = MulticlassMetrics(rf_rdd)\n",
    "rf_cm = rf_metrics.confusionMatrix().toArray()\n",
    "\n",
    "# Calculate the precision, recall and f1-score for \"No\" and \"Yes\".\n",
    "rf_precision_0 = rf_metrics.precision(0)\n",
    "rf_recall_0 = rf_metrics.recall(0)\n",
    "rf_f1_0 = rf_metrics.fMeasure(0.0)\n",
    "rf_precision_1 = rf_metrics.precision(1)\n",
    "rf_recall_1 = rf_metrics.recall(1)\n",
    "rf_f1_1 = rf_metrics.fMeasure(1.0)\n",
    "\n",
    "# Print the result\n",
    "print(\"Confusion Matrix:\\n\",rf_cm)\n",
    "print(\"\\nRain tomorrow?\", \"      No       \", \"        Yes      \")\n",
    "print(\"Precision: \", rf_precision_0, rf_precision_1)\n",
    "print(\"Recall:    \", rf_recall_0, rf_recall_1)\n",
    "print(\"F1 score:  \", rf_f1_0, rf_f1_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: In this confusion matrix, the positive value represents \"No rain\", and the negative value represents \"Rain tomorrow\". The rows represents the prediction, and the columns represents real condition.\n",
    "\n",
    "|Confusion Matrix|Condition Positive|Condition Negative|\n",
    "|---|---|---|\n",
    "|Prediction Positive|True Positive|False Positive|\n",
    "|Prediction Negative|False Negative|True Negative|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regresstion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[31258.  1715.]\n",
      " [ 5220.  4285.]]\n",
      "\n",
      "Rain tomorrow?       No                Yes      \n",
      "Precision:  0.8569000493448106 0.7141666666666666\n",
      "Recall:     0.9479877475510265 0.4508153603366649\n",
      "F1 score:   0.9001454262717599 0.5527249274427605\n"
     ]
    }
   ],
   "source": [
    "# Calculate the confusion matrix\n",
    "lr_rdd = lr_prediction.select(\"prediction\", \"RainTomorrowIndex\").rdd\n",
    "lr_metrics = MulticlassMetrics(lr_rdd)\n",
    "lr_cm = lr_metrics.confusionMatrix().toArray()\n",
    "\n",
    "# Calculate the precision, recall and f1-score for \"No\" and \"Yes\".\n",
    "lr_precision_0 = lr_metrics.precision(0)\n",
    "lr_recall_0 = lr_metrics.recall(0)\n",
    "lr_f1_0 = lr_metrics.fMeasure(0.0)\n",
    "lr_precision_1 = lr_metrics.precision(1)\n",
    "lr_recall_1 = lr_metrics.recall(1)\n",
    "lr_f1_1 = lr_metrics.fMeasure(1.0)\n",
    "\n",
    "# Print the result\n",
    "print(\"Confusion Matrix:\\n\",lr_cm)\n",
    "print(\"\\nRain tomorrow?\", \"      No       \", \"        Yes      \")\n",
    "print(\"Precision: \", lr_precision_0, lr_precision_1)\n",
    "print(\"Recall:    \", lr_recall_0, lr_recall_1)\n",
    "print(\"F1 score:  \", lr_f1_0, lr_f1_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: In this confusion matrix, the positive value represents \"No rain\", and the negative value represents \"Rain tomorrow\". The rows represents the prediction, and the columns represents real condition.\n",
    "\n",
    "|Confusion Matrix|Condition Positive|Condition Negative|\n",
    "|---|---|---|\n",
    "|Prediction Positive|True Positive|False Positive|\n",
    "|Prediction Negative|False Negative|True Negative|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosted Trees(GBT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[31244.  1729.]\n",
      " [ 4910.  4595.]]\n",
      "\n",
      "Rain tomorrow?       No                Yes      \n",
      "Precision:  0.8641920672677988 0.7265970904490828\n",
      "Recall:     0.9475631577351166 0.48342977380326146\n",
      "F1 score:   0.903959379113805 0.5805799481963484\n"
     ]
    }
   ],
   "source": [
    "# Calculate the confusion matrix\n",
    "gbt_rdd = gbt_prediction.select(\"prediction\", \"RainTomorrowIndex\").rdd\n",
    "gbt_metrics = MulticlassMetrics(gbt_rdd)\n",
    "gbt_cm = gbt_metrics.confusionMatrix().toArray()\n",
    "\n",
    "# Calculate the precision, recall and f1-score for \"No\" and \"Yes\".\n",
    "gbt_precision_0 = gbt_metrics.precision(0)\n",
    "gbt_recall_0 = gbt_metrics.recall(0)\n",
    "gbt_f1_0 = gbt_metrics.fMeasure(0.0)\n",
    "gbt_precision_1 = gbt_metrics.precision(1)\n",
    "gbt_recall_1 = gbt_metrics.recall(1)\n",
    "gbt_f1_1 = gbt_metrics.fMeasure(1.0)\n",
    "\n",
    "# Print the result\n",
    "print(\"Confusion Matrix:\\n\",gbt_cm)\n",
    "print(\"\\nRain tomorrow?\", \"      No       \", \"        Yes      \")\n",
    "print(\"Precision: \", gbt_precision_0, gbt_precision_1)\n",
    "print(\"Recall:    \", gbt_recall_0, gbt_recall_1)\n",
    "print(\"F1 score:  \", gbt_f1_0, gbt_f1_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: In this confusion matrix, the positive value represents \"No rain\", and the negative value represents \"Rain tomorrow\". The rows represents the prediction, and the columns represents real condition.\n",
    "\n",
    "|Confusion Matrix|Condition Positive|Condition Negative|\n",
    "|---|---|---|\n",
    "|Prediction Positive|True Positive|False Positive|\n",
    "|Prediction Negative|False Negative|True Negative|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improvement\n",
    "In this case, there are some ways to improve the accuracy of the predication:\n",
    "\n",
    "1. Using cross-validation for each algorithm. Divide the dataset into several parts. For each part, apply the algorithm and calculate the accuracy. At last, use the average accuracy as the model accuracy.\n",
    "\n",
    "2. Deal with the outlier. The outlier can not reflect the real relation between features and prediction. The model will be more accurate without outliers.\n",
    "\n",
    "3. Feature scaling. Standardize the range of features, to make sure different features have the same scale. Avoid the influence from different scale.\n",
    "\n",
    "4. Obtain more training data. Large dataset can reduce the uncertainty of the prediction result, also increase stability of the model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
